{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106d1934-85ae-4a59-b2dc-019c27b1af20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b09fc8ad-74c9-47e3-9ef3-a20d4cfb7b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: {3: {'Strong': {0: {'Overcast': 'Yes', 'Rainy': 'No', 'Sunny': 'No'}}, 'Weak': 'Yes'}}\n",
      "Prediction for ['Sunny', 'Cool', 'Normal', 'Weak']: Yes\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Helper function to calculate entropy\n",
    "def entropy(data):\n",
    "    labels = [row[-1] for row in data]\n",
    "    label_counts = {label: labels.count(label) for label in set(labels)}\n",
    "    total = len(data)\n",
    "    return -sum((count / total) * math.log2(count / total) for count in label_counts.values())\n",
    "\n",
    "# Helper function to calculate information gain\n",
    "def information_gain(data, feature_index):\n",
    "    total_entropy = entropy(data)\n",
    "    feature_values = [row[feature_index] for row in data]\n",
    "    unique_values = set(feature_values)\n",
    "    \n",
    "    weighted_entropy = 0\n",
    "    for value in unique_values:\n",
    "        subset = [row for row in data if row[feature_index] == value]\n",
    "        weighted_entropy += (len(subset) / len(data)) * entropy(subset)\n",
    "    \n",
    "    return total_entropy - weighted_entropy\n",
    "\n",
    "# Helper function to get the best feature to split on\n",
    "def best_split(data):\n",
    "    best_gain = -float('inf')\n",
    "    best_feature_index = -1\n",
    "    for feature_index in range(len(data[0]) - 1):  # Last column is the label\n",
    "        gain = information_gain(data, feature_index)\n",
    "        if gain > best_gain:\n",
    "            best_gain = gain\n",
    "            best_feature_index = feature_index\n",
    "    return best_feature_index\n",
    "\n",
    "# Decision tree algorithm\n",
    "def build_tree(data):\n",
    "    labels = [row[-1] for row in data]\n",
    "    \n",
    "    # If all examples have the same label, return a leaf node\n",
    "    if len(set(labels)) == 1:\n",
    "        return labels[0]\n",
    "    \n",
    "    # If there are no features left to split on, return the most common label\n",
    "    if len(data[0]) == 1:\n",
    "        return max(set(labels), key=labels.count)\n",
    "    \n",
    "    best_feature = best_split(data)\n",
    "    \n",
    "    tree = {best_feature: {}}\n",
    "    feature_values = set([row[best_feature] for row in data])\n",
    "    \n",
    "    for value in feature_values:\n",
    "        subset = [row for row in data if row[best_feature] == value]\n",
    "        tree[best_feature][value] = build_tree([row[:best_feature] + row[best_feature+1:] for row in subset])\n",
    "    \n",
    "    return tree\n",
    "\n",
    "# Function to classify a new example\n",
    "def classify(tree, example):\n",
    "    if not isinstance(tree, dict):  # If it's a leaf node\n",
    "        return tree\n",
    "    \n",
    "    feature = list(tree.keys())[0]\n",
    "    feature_value = example[feature]\n",
    "    \n",
    "    return classify(tree[feature].get(feature_value), example)\n",
    "\n",
    "# Sample data (using categorical values for features + label)\n",
    "data = [\n",
    "    ['Sunny', 'Hot', 'High', 'Weak', 'Yes'],\n",
    "    ['Sunny', 'Hot', 'High', 'Strong', 'No'],\n",
    "    ['Overcast', 'Hot', 'High', 'Weak', 'Yes'],\n",
    "    ['Rainy', 'Mild', 'High', 'Weak', 'Yes'],\n",
    "    ['Rainy', 'Cool', 'Normal', 'Weak', 'Yes'],\n",
    "    ['Rainy', 'Cool', 'Normal', 'Strong', 'No'],\n",
    "    ['Overcast', 'Cool', 'Normal', 'Strong', 'Yes'],\n",
    "    ['Sunny', 'Mild', 'High', 'Weak', 'Yes'],\n",
    "    ['Sunny', 'Cool', 'Normal', 'Weak', 'Yes'],\n",
    "    ['Rainy', 'Mild', 'Normal', 'Weak', 'Yes'],\n",
    "    ['Sunny', 'Mild', 'Normal', 'Strong', 'No'],\n",
    "    ['Overcast', 'Mild', 'High', 'Strong', 'Yes'],\n",
    "    ['Overcast', 'Hot', 'Normal', 'Weak', 'Yes'],\n",
    "    ['Rainy', 'Mild', 'High', 'Strong', 'No']\n",
    "]\n",
    "\n",
    "# Feature names (optional, for better understanding)\n",
    "features = ['Outlook', 'Temperature', 'Humidity', 'Wind']\n",
    "\n",
    "# Build the tree\n",
    "tree = build_tree(data)\n",
    "\n",
    "# Print the tree\n",
    "print(\"Decision Tree:\", tree)\n",
    "\n",
    "# Classify new examples\n",
    "new_example = ['Sunny', 'Cool', 'Normal', 'Weak']  # Example with features ['Sunny', 'Cool', 'Normal', 'Weak']\n",
    "print(\"Prediction for ['Sunny', 'Cool', 'Normal', 'Weak']:\", classify(tree, new_example))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205e0eea-bdfa-4d5c-aa7c-485db58e3038",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
